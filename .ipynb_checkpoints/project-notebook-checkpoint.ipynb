{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66b21b0e",
   "metadata": {},
   "source": [
    "# CLEF2023 Task 2: Subjectivity in news articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6736f8ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-14T21:22:35.648440Z",
     "iopub.status.busy": "2023-07-14T21:22:35.647773Z",
     "iopub.status.idle": "2023-07-14T21:22:35.694520Z",
     "shell.execute_reply": "2023-07-14T21:22:35.693293Z",
     "shell.execute_reply.started": "2023-07-14T21:22:35.648387Z"
    }
   },
   "outputs": [],
   "source": [
    "# All imports\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from datasets import Dataset, DatasetDict\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "aae5ae03",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-14T21:12:23.546380Z",
     "iopub.status.busy": "2023-07-14T21:12:23.545053Z",
     "iopub.status.idle": "2023-07-14T21:12:23.602390Z",
     "shell.execute_reply": "2023-07-14T21:12:23.601115Z",
     "shell.execute_reply.started": "2023-07-14T21:12:23.546335Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Reading the dataset\n",
    "train_data = pd.read_csv('./data/subtask-2-english/train_en.tsv', delimiter='\\t')\n",
    "validation_data = pd.read_csv('./data/subtask-2-english/dev_en.tsv', delimiter='\\t')\n",
    "testing_data = pd.read_csv('./data/subtask-2-english/test_en.tsv', delimiter='\\t')\n",
    "testing_data_gold = pd.read_csv('./data/subtask-2-english/test_en_gold.tsv', delimiter='\\t')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cab8df3a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-14T21:12:24.179395Z",
     "iopub.status.busy": "2023-07-14T21:12:24.178983Z",
     "iopub.status.idle": "2023-07-14T21:12:24.186511Z",
     "shell.execute_reply": "2023-07-14T21:12:24.185176Z",
     "shell.execute_reply.started": "2023-07-14T21:12:24.179360Z"
    }
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "def remove_punctuation(text):\n",
    "    cleaned_text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    return cleaned_text\n",
    "\n",
    "def remove_numbers(text):\n",
    "    cleaned_text = re.sub(r'\\d+', '', text)\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ad3a4bdf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-14T21:12:25.926071Z",
     "iopub.status.busy": "2023-07-14T21:12:25.925639Z",
     "iopub.status.idle": "2023-07-14T21:12:25.974402Z",
     "shell.execute_reply": "2023-07-14T21:12:25.972780Z",
     "shell.execute_reply.started": "2023-07-14T21:12:25.926039Z"
    }
   },
   "outputs": [],
   "source": [
    "for data in [train_data, validation_data, testing_data, testing_data_gold]:\n",
    "    data['sentence'] = data['sentence'].apply(remove_punctuation)\n",
    "    data['sentence'] = data['sentence'].apply(remove_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ce8a2533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['sentence_id', 'sentence', 'label', 'solved_conflict'],\n",
      "        num_rows: 830\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['sentence_id', 'sentence', 'label', 'solved_conflict'],\n",
      "        num_rows: 219\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['sentence_id', 'sentence', 'label'],\n",
      "        num_rows: 243\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_data['label'] = train_data['label'].replace({'SUBJ': 0, 'OBJ': 1})\n",
    "validation_data['label'] = validation_data['label'].replace({'SUBJ': 0, 'OBJ': 1})\n",
    "testing_data_gold['label'] = testing_data_gold['label'].replace({'SUBJ': 0, 'OBJ': 1})\n",
    "\n",
    "# Convert to Hugging Face Dataset format\n",
    "train_dataset = Dataset.from_pandas(train_data)\n",
    "validation_dataset = Dataset.from_pandas(validation_data)\n",
    "testing_dataset = Dataset.from_pandas(testing_data)\n",
    "testing_data_gold = Dataset.from_pandas(testing_data_gold)\n",
    "\n",
    "# Create DatasetDict\n",
    "dataset_dict = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'validation': validation_dataset,\n",
    "    'test': testing_data_gold,\n",
    "})\n",
    "\n",
    "print(dataset_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "777ffac9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cb561377d4c49b88f954d22f795540b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68dc6f5f74404511af5b101c8ae99335",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43817dafd8e340d3a3a932d0e9b648e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca8eef657d0f45be8d59d1513bd2823f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import numpy as np\n",
    "\n",
    "roberta_tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "28b19e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "\n",
    "    \"\"\" This function tokenizes the text in the examples dictionary.\n",
    "        We pass it to the map function of the dataset so that we can batch the tokenization for efficiency by\n",
    "        tokenizing batches in parallel.\n",
    "    \"\"\"\n",
    "    return roberta_tokenizer(examples[\"sentence\"], padding=\"max_length\", truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "af8bd39e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/830 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/219 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/243 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_datasets = dataset_dict.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b5897c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Normalize numerical features in the training set\n",
    "train_features = scaler.fit_transform(tokenized_datasets[\"train\"][\"input_ids\"])\n",
    "\n",
    "# Apply the same transformation to the validation and test sets\n",
    "validation_features = scaler.transform(tokenized_datasets[\"validation\"][\"input_ids\"])\n",
    "test_features = scaler.transform(tokenized_datasets[\"test\"][\"input_ids\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "83e762da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(830,)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['label'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "eb03f985",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-14T21:12:28.696795Z",
     "iopub.status.busy": "2023-07-14T21:12:28.695181Z",
     "iopub.status.idle": "2023-07-14T21:12:35.742911Z",
     "shell.execute_reply": "2023-07-14T21:12:35.741513Z",
     "shell.execute_reply.started": "2023-07-14T21:12:28.696727Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ahmad/.local/lib/python3.10/site-packages/torch/cuda/__init__.py:546: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/home/ahmad/.local/lib/python3.10/site-packages/torch/cuda/__init__.py:651: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 803: system has unsupported display driver / cuda driver combination (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return torch._C._cuda_getDeviceCount() if nvml_count < 0 else nvml_count\n"
     ]
    }
   ],
   "source": [
    "# !python3 -m spacy download en_core_web_lg\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "88bfbe9c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-14T21:12:35.745579Z",
     "iopub.status.busy": "2023-07-14T21:12:35.745212Z",
     "iopub.status.idle": "2023-07-14T21:12:35.751860Z",
     "shell.execute_reply": "2023-07-14T21:12:35.750966Z",
     "shell.execute_reply.started": "2023-07-14T21:12:35.745548Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, y_train = train_features, train_data['label']\n",
    "X_test, y_test = test_features, testing_data_gold['label']\n",
    "X_val, y_val = validation_features, validation_data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cc5e9f6b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-14T21:12:35.753768Z",
     "iopub.status.busy": "2023-07-14T21:12:35.753395Z",
     "iopub.status.idle": "2023-07-14T21:12:52.142911Z",
     "shell.execute_reply": "2023-07-14T21:12:52.141779Z",
     "shell.execute_reply.started": "2023-07-14T21:12:35.753707Z"
    }
   },
   "outputs": [],
   "source": [
    "train_vectors = X_train\n",
    "val_vectors = X_val\n",
    "test_vectors = X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3761ef41",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-14T14:29:22.237172Z",
     "iopub.status.busy": "2023-07-14T14:29:22.236680Z",
     "iopub.status.idle": "2023-07-14T14:29:22.251236Z",
     "shell.execute_reply": "2023-07-14T14:29:22.249733Z",
     "shell.execute_reply.started": "2023-07-14T14:29:22.237128Z"
    }
   },
   "source": [
    "## Baseline model MLPClasifier\n",
    "First we will use grid search for hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4e0f8268",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-14T21:13:11.268490Z",
     "iopub.status.busy": "2023-07-14T21:13:11.268105Z",
     "iopub.status.idle": "2023-07-14T21:20:03.981778Z",
     "shell.execute_reply": "2023-07-14T21:20:03.980643Z",
     "shell.execute_reply.started": "2023-07-14T21:13:11.268459Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20min 1s, sys: 31min 35s, total: 51min 36s\n",
      "Wall time: 6min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split, ParameterGrid\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(100,), (50, 50), (50, 25, 10)],\n",
    "    'activation': [ 'logistic', 'tanh', 'relu'],\n",
    "    'alpha': [0.0001, 0.001, 0.01],\n",
    "    'solver' : ['sgd', 'adam']\n",
    "}\n",
    "\n",
    "mlp = MLPClassifier(random_state=101)\n",
    "\n",
    "\n",
    "mlp_grid = ParameterGrid(param_grid)\n",
    "\n",
    "y_val_series = pd.Series(y_val).replace({'SUBJ': 0, 'OBJ': 1})\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_train_vectors = scaler.fit_transform(train_vectors)\n",
    "scaled_val_vectors = scaler.transform(val_vectors)\n",
    "\n",
    "data = []\n",
    "head = ['hidden_layer_sizes', 'activation', 'alpha', 'score in validation set']\n",
    "\n",
    "i = 0\n",
    "\n",
    "for param in mlp_grid:\n",
    "    mlp_model = MLPClassifier(max_iter = 5000, random_state=0, **param)\n",
    "    mlp_model.fit(scaled_train_vectors, y_train)\n",
    "    \n",
    "    predictions = mlp_model.predict(scaled_val_vectors)\n",
    "    predictions_series = pd.Series(predictions).replace({'SUBJ': 0, 'OBJ': 1})\n",
    "    \n",
    "    score = f1_score(y_val_series, predictions_series)\n",
    "    list_entry = [param['hidden_layer_sizes'], param['activation'], param['alpha'], param['solver'], score]\n",
    "    data.insert(0, list_entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ea78393c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-14T21:22:40.026483Z",
     "iopub.status.busy": "2023-07-14T21:22:40.026016Z",
     "iopub.status.idle": "2023-07-14T21:22:40.048104Z",
     "shell.execute_reply": "2023-07-14T21:22:40.046473Z",
     "shell.execute_reply.started": "2023-07-14T21:22:40.026447Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|              | hidden_layer_sizes   |   activation | alpha   |   score in validation set |\n",
      "|:-------------|:---------------------|-------------:|:--------|--------------------------:|\n",
      "| (50, 25, 10) | relu                 |       0.01   | adam    |                  0.583333 |\n",
      "| (50, 25, 10) | relu                 |       0.01   | sgd     |                  0.597701 |\n",
      "| (50, 50)     | relu                 |       0.01   | adam    |                  0.548263 |\n",
      "| (50, 50)     | relu                 |       0.01   | sgd     |                  0.561538 |\n",
      "| (100,)       | relu                 |       0.01   | adam    |                  0.593156 |\n",
      "| (100,)       | relu                 |       0.01   | sgd     |                  0.593407 |\n",
      "| (50, 25, 10) | relu                 |       0.001  | adam    |                  0.602941 |\n",
      "| (50, 25, 10) | relu                 |       0.001  | sgd     |                  0.606061 |\n",
      "| (50, 50)     | relu                 |       0.001  | adam    |                  0.574713 |\n",
      "| (50, 50)     | relu                 |       0.001  | sgd     |                  0.539062 |\n",
      "| (100,)       | relu                 |       0.001  | adam    |                  0.603774 |\n",
      "| (100,)       | relu                 |       0.001  | sgd     |                  0.595588 |\n",
      "| (50, 25, 10) | relu                 |       0.0001 | adam    |                  0.612546 |\n",
      "| (50, 25, 10) | relu                 |       0.0001 | sgd     |                  0.60076  |\n",
      "| (50, 50)     | relu                 |       0.0001 | adam    |                  0.562738 |\n",
      "| (50, 50)     | relu                 |       0.0001 | sgd     |                  0.551724 |\n",
      "| (100,)       | relu                 |       0.0001 | adam    |                  0.59176  |\n",
      "| (100,)       | relu                 |       0.0001 | sgd     |                  0.595588 |\n",
      "| (50, 25, 10) | tanh                 |       0.01   | adam    |                  0.587786 |\n",
      "| (50, 25, 10) | tanh                 |       0.01   | sgd     |                  0.608696 |\n",
      "| (50, 50)     | tanh                 |       0.01   | adam    |                  0.613718 |\n",
      "| (50, 50)     | tanh                 |       0.01   | sgd     |                  0.607692 |\n",
      "| (100,)       | tanh                 |       0.01   | adam    |                  0.592308 |\n",
      "| (100,)       | tanh                 |       0.01   | sgd     |                  0.612245 |\n",
      "| (50, 25, 10) | tanh                 |       0.001  | adam    |                  0.592308 |\n",
      "| (50, 25, 10) | tanh                 |       0.001  | sgd     |                  0.608696 |\n",
      "| (50, 50)     | tanh                 |       0.001  | adam    |                  0.618705 |\n",
      "| (50, 50)     | tanh                 |       0.001  | sgd     |                  0.607692 |\n",
      "| (100,)       | tanh                 |       0.001  | adam    |                  0.611321 |\n",
      "| (100,)       | tanh                 |       0.001  | sgd     |                  0.612245 |\n",
      "| (50, 25, 10) | tanh                 |       0.0001 | adam    |                  0.592308 |\n",
      "| (50, 25, 10) | tanh                 |       0.0001 | sgd     |                  0.608696 |\n",
      "| (50, 50)     | tanh                 |       0.0001 | adam    |                  0.618705 |\n",
      "| (50, 50)     | tanh                 |       0.0001 | sgd     |                  0.607692 |\n",
      "| (100,)       | tanh                 |       0.0001 | adam    |                  0.619926 |\n",
      "| (100,)       | tanh                 |       0.0001 | sgd     |                  0.612245 |\n",
      "| (50, 25, 10) | logistic             |       0.01   | adam    |                  0.59364  |\n",
      "| (50, 25, 10) | logistic             |       0.01   | sgd     |                  0.652308 |\n",
      "| (50, 50)     | logistic             |       0.01   | adam    |                  0.603636 |\n",
      "| (50, 50)     | logistic             |       0.01   | sgd     |                  0.652308 |\n",
      "| (100,)       | logistic             |       0.01   | adam    |                  0.602151 |\n",
      "| (100,)       | logistic             |       0.01   | sgd     |                  0.652308 |\n",
      "| (50, 25, 10) | logistic             |       0.001  | adam    |                  0.621908 |\n",
      "| (50, 25, 10) | logistic             |       0.001  | sgd     |                  0.652308 |\n",
      "| (50, 50)     | logistic             |       0.001  | adam    |                  0.609929 |\n",
      "| (50, 50)     | logistic             |       0.001  | sgd     |                  0.652308 |\n",
      "| (100,)       | logistic             |       0.001  | adam    |                  0.594982 |\n",
      "| (100,)       | logistic             |       0.001  | sgd     |                  0.652308 |\n",
      "| (50, 25, 10) | logistic             |       0.0001 | adam    |                  0.61324  |\n",
      "| (50, 25, 10) | logistic             |       0.0001 | sgd     |                  0.652308 |\n",
      "| (50, 50)     | logistic             |       0.0001 | adam    |                  0.614841 |\n",
      "| (50, 50)     | logistic             |       0.0001 | sgd     |                  0.652308 |\n",
      "| (100,)       | logistic             |       0.0001 | adam    |                  0.597122 |\n",
      "| (100,)       | logistic             |       0.0001 | sgd     |                  0.652308 |\n",
      "The highest Accuracy 0.652308 is the model model with hidden_layer_sizes = (50, 25, 10), activation = logistic, alpha = 0.010000, solver = sgd\n"
     ]
    }
   ],
   "source": [
    "print(tabulate(data, headers=head, tablefmt=\"pipe\"))\n",
    "max_accuracy = max(entry[4] for entry in data)\n",
    "best_model = next(item for item in data if item[4] == max_accuracy)\n",
    "print(\"The highest Accuracy %f is the model model with hidden_layer_sizes = %s, activation = %s, alpha = %f, solver = %s\"%\n",
    "      (best_model[4], best_model[0], best_model[1], best_model[2], best_model[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "00b1e4e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-14T21:22:46.283225Z",
     "iopub.status.busy": "2023-07-14T21:22:46.282784Z",
     "iopub.status.idle": "2023-07-14T21:22:49.129122Z",
     "shell.execute_reply": "2023-07-14T21:22:49.127360Z",
     "shell.execute_reply.started": "2023-07-14T21:22:46.283190Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MLP model with hidden_layer_sizes = (50, 25, 10), activation = logistic, alpha = 0.010000 has 0.4773662551440329 accuracy.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.00000   0.00000   0.00000       127\n",
      "           1    0.47737   1.00000   0.64624       116\n",
      "\n",
      "    accuracy                        0.47737       243\n",
      "   macro avg    0.23868   0.50000   0.32312       243\n",
      "weighted avg    0.22788   0.47737   0.30849       243\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ahmad/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ahmad/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ahmad/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ahmad/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, precision_recall_fscore_support\n",
    "\n",
    "best_mlp_model = MLPClassifier(hidden_layer_sizes=best_model[0], activation=best_model[1], alpha=best_model[2], solver ='sgd', random_state=0)\n",
    "best_mlp_model.fit(train_vectors, y_train)\n",
    "y_pred = best_mlp_model.predict(test_vectors)\n",
    "mlp_accuracy = best_mlp_model.score(test_vectors, y_test)\n",
    "mlp_f_score = precision_recall_fscore_support(y_test, y_pred, average='macro')[2]\n",
    "print(\"The MLP model with hidden_layer_sizes = %s, activation = %s, alpha = %f has %s accuracy.\"\n",
    "      % (best_model[0], best_model[1], best_model[2], mlp_accuracy))\n",
    "mlp_report = classification_report(y_test, y_pred, digits=5)\n",
    "print(mlp_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c64d0b18",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-14T21:22:55.520139Z",
     "iopub.status.busy": "2023-07-14T21:22:55.519781Z",
     "iopub.status.idle": "2023-07-14T21:22:56.059497Z",
     "shell.execute_reply": "2023-07-14T21:22:56.058312Z",
     "shell.execute_reply.started": "2023-07-14T21:22:55.520110Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 200x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "con_matrix = pd.crosstab(pd.Series(pd.DataFrame(y_test).values.flatten(), name='Actual'), pd.Series(pd.DataFrame(y_pred).values.flatten(), name='Predicted'))\n",
    "plt.figure(figsize=(2, 2))\n",
    "plt.title(\"Confusion Matrix on MLP\")\n",
    "sns.heatmap(con_matrix, cmap=\"Greys\", annot=True, fmt='g')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4daa8aa6",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f592d57b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-14T21:22:59.152448Z",
     "iopub.status.busy": "2023-07-14T21:22:59.151068Z",
     "iopub.status.idle": "2023-07-14T21:26:08.476947Z",
     "shell.execute_reply": "2023-07-14T21:26:08.475736Z",
     "shell.execute_reply.started": "2023-07-14T21:22:59.152378Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   C | kernel   |   score in validation set |\n",
      "|----:|:---------|--------------------------:|\n",
      "| 100 | rbf      |                 0.0186916 |\n",
      "| 100 | poly     |                 0.4375    |\n",
      "| 100 | linear   |                 0.59589   |\n",
      "| 100 | sigmoid  |                 0.510204  |\n",
      "|  10 | rbf      |                 0         |\n",
      "|  10 | poly     |                 0.509434  |\n",
      "|  10 | linear   |                 0.611111  |\n",
      "|  10 | sigmoid  |                 0.487562  |\n",
      "|   1 | rbf      |                 0.652308  |\n",
      "|   1 | poly     |                 0.492611  |\n",
      "|   1 | linear   |                 0.62585   |\n",
      "|   1 | sigmoid  |                 0.571429  |\n",
      "The highest Accuracy 0.652308 is the model model with C = 1 and used rbf kernal\n",
      "CPU times: user 2.05 s, sys: 0 ns, total: 2.05 s\n",
      "Wall time: 2.05 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "head = ['C','kernel','score in validation set']\n",
    "\n",
    "data =[]\n",
    "\n",
    "svm_param_grid = {'C': [1, 10, 100], 'kernel': ['sigmoid', 'linear', 'poly', 'rbf']}\n",
    "\n",
    "svm_grid = ParameterGrid(svm_param_grid)\n",
    "\n",
    "i = 0\n",
    "for param in svm_grid:\n",
    "    svm_model = SVC(**param)  \n",
    "    svm_model.fit(train_vectors, y_train)\n",
    "    \n",
    "    predictions = svm_model.predict(scaled_val_vectors)\n",
    "    predictions_series = pd.Series(predictions).replace({'SUBJ': 0, 'OBJ': 1})\n",
    "    \n",
    "    score = f1_score(y_val_series, predictions_series)\n",
    "        \n",
    "    list_entry = [param['C'],  param['kernel'],score]\n",
    "    data.insert(0,list_entry)\n",
    "    \n",
    "print(tabulate(data, headers=head, tablefmt=\"pipe\"))\n",
    "max_accuracy = max(entry[2] for entry in data)\n",
    "for item in data:\n",
    "    if item[2] == max_accuracy:\n",
    "        best_model = item\n",
    "print(\"The highest Accuracy %f is the model model with C = %d and used %s kernal\" %\n",
    "                (best_model[2],best_model[0],best_model[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4d93b06c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-14T21:26:08.478992Z",
     "iopub.status.busy": "2023-07-14T21:26:08.478631Z",
     "iopub.status.idle": "2023-07-14T21:26:08.626922Z",
     "shell.execute_reply": "2023-07-14T21:26:08.625789Z",
     "shell.execute_reply.started": "2023-07-14T21:26:08.478960Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The SVM model with C = 1 and used Linear basis function as kernel has 0.551440329218107 accuracy with this classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.67308   0.27559   0.39106       127\n",
      "           1    0.51832   0.85345   0.64495       116\n",
      "\n",
      "    accuracy                        0.55144       243\n",
      "   macro avg    0.59570   0.56452   0.51801       243\n",
      "weighted avg    0.59920   0.55144   0.51226       243\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm_model = SVC(C = 10, kernel='poly')\n",
    "svm_model.fit(train_vectors, y_train)\n",
    "svm_accuracy=svm_model.score(test_vectors, y_test)\n",
    "predictions = svm_model.predict(test_vectors)\n",
    "svm_f_score = precision_recall_fscore_support(y_test,predictions, average='macro')[2]\n",
    "print(\"The SVM model with C = %d and used %s as kernel has %s accuracy with this classification report\"\n",
    "      % (1,\"Linear basis function\", svm_accuracy))\n",
    "svm_report = classification_report(y_test,predictions,digits = 5)\n",
    "print(svm_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b77cae11",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-14T21:26:08.629239Z",
     "iopub.status.busy": "2023-07-14T21:26:08.628466Z",
     "iopub.status.idle": "2023-07-14T21:26:08.861930Z",
     "shell.execute_reply": "2023-07-14T21:26:08.860623Z",
     "shell.execute_reply.started": "2023-07-14T21:26:08.629198Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 200x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "con_matrix = pd.crosstab(pd.Series(pd.DataFrame(y_test).values.flatten(), name='Actual'),\n",
    "                         pd.Series(pd.DataFrame(predictions).values.flatten(), name='Predicted'))\n",
    "plt.figure(figsize=(2, 2))\n",
    "plt.title(\"Confusion Matrix on SVM\")\n",
    "sns.heatmap(con_matrix, cmap=\"Greys\", annot=True, fmt='g')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee826922",
   "metadata": {},
   "source": [
    "# Random Forrest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3dbc404a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-14T21:26:08.865457Z",
     "iopub.status.busy": "2023-07-14T21:26:08.865005Z",
     "iopub.status.idle": "2023-07-14T21:26:28.709858Z",
     "shell.execute_reply": "2023-07-14T21:26:28.708650Z",
     "shell.execute_reply.started": "2023-07-14T21:26:08.865405Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|     | n_estimators   |   criterion | max_depth   |   score in validation set |\n",
      "|----:|:---------------|------------:|:------------|--------------------------:|\n",
      "| 100 | gini           |         100 | log2        |                  0.642384 |\n",
      "|  50 | gini           |         100 | log2        |                  0.581395 |\n",
      "|  10 | gini           |         100 | log2        |                  0.552239 |\n",
      "| 100 | gini           |         100 | sqrt        |                  0.62116  |\n",
      "|  50 | gini           |         100 | sqrt        |                  0.589928 |\n",
      "|  10 | gini           |         100 | sqrt        |                  0.566176 |\n",
      "| 100 | gini           |          50 | log2        |                  0.582192 |\n",
      "|  50 | gini           |          50 | log2        |                  0.610169 |\n",
      "|  10 | gini           |          50 | log2        |                  0.461538 |\n",
      "| 100 | gini           |          50 | sqrt        |                  0.630137 |\n",
      "|  50 | gini           |          50 | sqrt        |                  0.641892 |\n",
      "|  10 | gini           |          50 | sqrt        |                  0.5625   |\n",
      "| 100 | gini           |          10 | log2        |                  0.662379 |\n",
      "|  50 | gini           |          10 | log2        |                  0.640777 |\n",
      "|  10 | gini           |          10 | log2        |                  0.614815 |\n",
      "| 100 | gini           |          10 | sqrt        |                  0.632588 |\n",
      "|  50 | gini           |          10 | sqrt        |                  0.625806 |\n",
      "|  10 | gini           |          10 | sqrt        |                  0.627306 |\n",
      "| 100 | entropy        |         100 | log2        |                  0.643533 |\n",
      "|  50 | entropy        |         100 | log2        |                  0.61324  |\n",
      "|  10 | entropy        |         100 | log2        |                  0.617647 |\n",
      "| 100 | entropy        |         100 | sqrt        |                  0.644951 |\n",
      "|  50 | entropy        |         100 | sqrt        |                  0.623656 |\n",
      "|  10 | entropy        |         100 | sqrt        |                  0.571429 |\n",
      "| 100 | entropy        |          50 | log2        |                  0.642623 |\n",
      "|  50 | entropy        |          50 | log2        |                  0.631229 |\n",
      "|  10 | entropy        |          50 | log2        |                  0.618705 |\n",
      "| 100 | entropy        |          50 | sqrt        |                  0.640523 |\n",
      "|  50 | entropy        |          50 | sqrt        |                  0.649351 |\n",
      "|  10 | entropy        |          50 | sqrt        |                  0.577406 |\n",
      "| 100 | entropy        |          10 | log2        |                  0.654088 |\n",
      "|  50 | entropy        |          10 | log2        |                  0.616949 |\n",
      "|  10 | entropy        |          10 | log2        |                  0.659864 |\n",
      "| 100 | entropy        |          10 | sqrt        |                  0.624606 |\n",
      "|  50 | entropy        |          10 | sqrt        |                  0.651899 |\n",
      "|  10 | entropy        |          10 | sqrt        |                  0.622837 |\n",
      "The highest Accuracy 0.662379 is the model model with n_estimators = 100 and used gini criterion with max_depth = 10 and max_features splitter log2\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "head = ['n_estimators','criterion','max_depth','score in validation set']\n",
    "data =[]\n",
    "rf_param_grid = {'n_estimators': [10, 50, 100], 'criterion': ['entropy', 'gini'],\n",
    "                'max_depth': [10, 50, 100],\n",
    "                'max_features': [\"sqrt\", \"log2\"]}\n",
    "rf_grid = ParameterGrid(rf_param_grid)\n",
    "for param in rf_grid:\n",
    "    rf_model = RandomForestClassifier(**param)  \n",
    "    rf_model.fit(train_vectors, y_train)\n",
    "    \n",
    "    predictions = rf_model.predict(scaled_val_vectors)\n",
    "    predictions_series = pd.Series(predictions).replace({'SUBJ': 0, 'OBJ': 1})\n",
    "    \n",
    "    score = f1_score(y_val_series, predictions_series)\n",
    "    \n",
    "    list_entry = [param['n_estimators'],  param['criterion'], param['max_depth'], param['max_features'],score]\n",
    "\n",
    "    data.insert(0,list_entry)\n",
    "print(tabulate(data, headers=head, tablefmt=\"pipe\"))\n",
    "max_accuracy = max(entry[4] for entry in data)\n",
    "for item in data:\n",
    "    if item[4] == max_accuracy:\n",
    "        best_model = item\n",
    "print(\"The highest Accuracy %f is the model model with n_estimators = %d and used %s criterion with max_depth = %s and max_features splitter %s\"\n",
    "      % (best_model[4],best_model[0],best_model[1], best_model[2], best_model[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "935ec6f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-14T21:29:48.090097Z",
     "iopub.status.busy": "2023-07-14T21:29:48.089641Z",
     "iopub.status.idle": "2023-07-14T21:29:48.204194Z",
     "shell.execute_reply": "2023-07-14T21:29:48.203091Z",
     "shell.execute_reply.started": "2023-07-14T21:29:48.090064Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The RF Model with n_estimators = 10 and used entropy criterion with max_depth = 100 and max_features splitter log2 has 0.551440329218107 accuracy with this classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.49333   0.29134   0.36634       127\n",
      "           1    0.46429   0.67241   0.54930       116\n",
      "\n",
      "    accuracy                        0.47325       243\n",
      "   macro avg    0.47881   0.48188   0.45782       243\n",
      "weighted avg    0.47947   0.47325   0.45368       243\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_model = RandomForestClassifier(n_estimators = 10, max_depth = 100, max_features = 'log2', criterion = 'entropy')\n",
    "rf_model.fit(train_vectors, y_train)\n",
    "rf_accuracy=rf_model.score(test_vectors, y_test)\n",
    "predictions = rf_model.predict(test_vectors)\n",
    "rf_f_score = precision_recall_fscore_support(y_test,predictions, average='macro')[2]\n",
    "print(\"The RF Model with n_estimators = 10 and used entropy criterion with max_depth = 100 and max_features splitter log2 has %s accuracy with this classification report\"\n",
    "      % (svm_accuracy))\n",
    "svm_report = classification_report(y_test,predictions,digits = 5)\n",
    "print(svm_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "ba352a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "import sys\n",
    "import zipfile\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "1ebd70ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Requirement already satisfied: pytorch_pretrained_bert in /home/ahmad/exit/lib/python3.10/site-packages (0.6.2)\n",
      "Requirement already satisfied: torch>=0.4.1 in /home/ahmad/.local/lib/python3.10/site-packages (from pytorch_pretrained_bert) (2.0.1)\n",
      "Requirement already satisfied: numpy in /home/ahmad/.local/lib/python3.10/site-packages (from pytorch_pretrained_bert) (1.24.2)\n",
      "Requirement already satisfied: boto3 in /home/ahmad/exit/lib/python3.10/site-packages (from pytorch_pretrained_bert) (1.28.3)\n",
      "Requirement already satisfied: requests in /home/ahmad/exit/lib/python3.10/site-packages (from pytorch_pretrained_bert) (2.29.0)\n",
      "Requirement already satisfied: tqdm in /home/ahmad/.local/lib/python3.10/site-packages (from pytorch_pretrained_bert) (4.65.0)\n",
      "Requirement already satisfied: regex in /home/ahmad/exit/lib/python3.10/site-packages (from pytorch_pretrained_bert) (2023.6.3)\n",
      "Requirement already satisfied: filelock in /home/ahmad/exit/lib/python3.10/site-packages (from torch>=0.4.1->pytorch_pretrained_bert) (3.12.2)\n",
      "Requirement already satisfied: typing-extensions in /home/ahmad/.local/lib/python3.10/site-packages (from torch>=0.4.1->pytorch_pretrained_bert) (4.6.3)\n",
      "Requirement already satisfied: sympy in /home/ahmad/exit/lib/python3.10/site-packages (from torch>=0.4.1->pytorch_pretrained_bert) (1.11.1)\n",
      "Requirement already satisfied: networkx in /home/ahmad/.local/lib/python3.10/site-packages (from torch>=0.4.1->pytorch_pretrained_bert) (3.1)\n",
      "Requirement already satisfied: jinja2 in /home/ahmad/exit/lib/python3.10/site-packages (from torch>=0.4.1->pytorch_pretrained_bert) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/ahmad/.local/lib/python3.10/site-packages (from torch>=0.4.1->pytorch_pretrained_bert) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/ahmad/.local/lib/python3.10/site-packages (from torch>=0.4.1->pytorch_pretrained_bert) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /home/ahmad/.local/lib/python3.10/site-packages (from torch>=0.4.1->pytorch_pretrained_bert) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/ahmad/.local/lib/python3.10/site-packages (from torch>=0.4.1->pytorch_pretrained_bert) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/ahmad/.local/lib/python3.10/site-packages (from torch>=0.4.1->pytorch_pretrained_bert) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /home/ahmad/.local/lib/python3.10/site-packages (from torch>=0.4.1->pytorch_pretrained_bert) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /home/ahmad/.local/lib/python3.10/site-packages (from torch>=0.4.1->pytorch_pretrained_bert) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /home/ahmad/.local/lib/python3.10/site-packages (from torch>=0.4.1->pytorch_pretrained_bert) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /home/ahmad/.local/lib/python3.10/site-packages (from torch>=0.4.1->pytorch_pretrained_bert) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /home/ahmad/.local/lib/python3.10/site-packages (from torch>=0.4.1->pytorch_pretrained_bert) (2.14.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /home/ahmad/.local/lib/python3.10/site-packages (from torch>=0.4.1->pytorch_pretrained_bert) (11.7.91)\n",
      "Requirement already satisfied: triton==2.0.0 in /home/ahmad/.local/lib/python3.10/site-packages (from torch>=0.4.1->pytorch_pretrained_bert) (2.0.0)\n",
      "Requirement already satisfied: setuptools in /home/ahmad/exit/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=0.4.1->pytorch_pretrained_bert) (65.6.3)\n",
      "Requirement already satisfied: wheel in /home/ahmad/exit/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=0.4.1->pytorch_pretrained_bert) (0.38.4)\n",
      "Requirement already satisfied: cmake in /home/ahmad/.local/lib/python3.10/site-packages (from triton==2.0.0->torch>=0.4.1->pytorch_pretrained_bert) (3.26.4)\n",
      "Requirement already satisfied: lit in /home/ahmad/.local/lib/python3.10/site-packages (from triton==2.0.0->torch>=0.4.1->pytorch_pretrained_bert) (16.0.6)\n",
      "Requirement already satisfied: botocore<1.32.0,>=1.31.3 in /home/ahmad/exit/lib/python3.10/site-packages (from boto3->pytorch_pretrained_bert) (1.31.3)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/ahmad/exit/lib/python3.10/site-packages (from boto3->pytorch_pretrained_bert) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /home/ahmad/exit/lib/python3.10/site-packages (from boto3->pytorch_pretrained_bert) (0.6.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ahmad/exit/lib/python3.10/site-packages (from requests->pytorch_pretrained_bert) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ahmad/exit/lib/python3.10/site-packages (from requests->pytorch_pretrained_bert) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ahmad/exit/lib/python3.10/site-packages (from requests->pytorch_pretrained_bert) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ahmad/exit/lib/python3.10/site-packages (from requests->pytorch_pretrained_bert) (2023.5.7)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ahmad/exit/lib/python3.10/site-packages (from botocore<1.32.0,>=1.31.3->boto3->pytorch_pretrained_bert) (2.8.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ahmad/exit/lib/python3.10/site-packages (from jinja2->torch>=0.4.1->pytorch_pretrained_bert) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/ahmad/exit/lib/python3.10/site-packages (from sympy->torch>=0.4.1->pytorch_pretrained_bert) (1.3.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/ahmad/exit/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.32.0,>=1.31.3->boto3->pytorch_pretrained_bert) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pytorch_pretrained_bert "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ca17c5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM, BertForSequenceClassification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "87fa12a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "df6d9607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the dataset\n",
    "train = pd.read_csv('./data/subtask-2-english/train_en.tsv', delimiter='\\t', index_col = 'sentence_id')\n",
    "val = pd.read_csv('./data/subtask-2-english/dev_en.tsv', delimiter='\\t', index_col = 'sentence_id')\n",
    "#test = pd.read_csv('./data/subtask-2-english/test_en.tsv', delimiter='\\t', index_col = 'sentence_id')\n",
    "test = pd.read_csv('./data/subtask-2-english/test_en_gold.tsv', delimiter='\\t', index_col = 'sentence_id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "6b0cf9a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentence_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>b9e1635a-72aa-467f-86d6-f56ef09f62c3</th>\n",
       "      <td>Gone are the days when they led the world in r...</td>\n",
       "      <td>SUBJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f99b5143-70d2-494a-a2f5-c68f10d09d0a</th>\n",
       "      <td>The trend is expected to reverse as soon as ne...</td>\n",
       "      <td>OBJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4076639c-aa56-4202-ae0f-9d9217f8da68</th>\n",
       "      <td>But there is the specious point again.</td>\n",
       "      <td>OBJ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                               sentence  \\\n",
       "sentence_id                                                                               \n",
       "b9e1635a-72aa-467f-86d6-f56ef09f62c3  Gone are the days when they led the world in r...   \n",
       "f99b5143-70d2-494a-a2f5-c68f10d09d0a  The trend is expected to reverse as soon as ne...   \n",
       "4076639c-aa56-4202-ae0f-9d9217f8da68             But there is the specious point again.   \n",
       "\n",
       "                                     label  \n",
       "sentence_id                                 \n",
       "b9e1635a-72aa-467f-86d6-f56ef09f62c3  SUBJ  \n",
       "f99b5143-70d2-494a-a2f5-c68f10d09d0a   OBJ  \n",
       "4076639c-aa56-4202-ae0f-9d9217f8da68   OBJ  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['sentence', \n",
    "        'label']\n",
    "train = train.loc[:, cols]\n",
    "test = test.loc[:, cols]\n",
    "train.fillna('UNKNOWN', inplace=True)\n",
    "test.fillna('UNKNOWN', inplace=True)\n",
    "train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "755df1e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'OBJ': 532, 'SUBJ': 298})"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(train.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "b24381ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "--2023-07-15 14:07:47--  https://github.com/google-research/bert/blob/f39e881b169b9d53bea03d2d341b31707a6c052b/run_classifier.py\n",
      "Resolving github.com (github.com)... 140.82.121.3\n",
      "Connecting to github.com (github.com)|140.82.121.3|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 177266 (173K) [text/plain]\n",
      "Saving to: ‘run_classifier.py.3’\n",
      "\n",
      "run_classifier.py.3 100%[===================>] 173.11K  --.-KB/s    in 0.05s   \n",
      "\n",
      "2023-07-15 14:07:47 (3.20 MB/s) - ‘run_classifier.py.3’ saved [177266/177266]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/google-research/bert/blob/f39e881b169b9d53bea03d2d341b31707a6c052b/run_classifier.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "dd87e86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = ['OBJ', 'SUBJ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "41407868",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataclasses\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Optional, Union\n",
    "@dataclass\n",
    "class InputExample:\n",
    "    \"\"\"\n",
    "    A single training/test example for simple sequence classification.\n",
    "\n",
    "    Args:\n",
    "        guid: Unique id for the example.\n",
    "        text_a: string. The untokenized text of the first sequence. For single\n",
    "            sequence tasks, only this sequence must be specified.\n",
    "        text_b: (Optional) string. The untokenized text of the second sequence.\n",
    "            Only must be specified for sequence pair tasks.\n",
    "        label: (Optional) string. The label of the example. This should be\n",
    "            specified for train and dev examples, but not for test examples.\n",
    "    \"\"\"\n",
    "\n",
    "    sentence_id: str\n",
    "    text_a: str\n",
    "    text_b: Optional[str] = None\n",
    "    label: Optional[str] = None\n",
    "\n",
    "    def to_json_string(self):\n",
    "        \"\"\"Serializes this instance to a JSON string.\"\"\"\n",
    "        return json.dumps(dataclasses.asdict(self), indent=2) + \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "521929da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "830"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train_examples = [InputExample(row.Index, row.sentence, label = row.label) for row in train.itertuples()]\n",
    "val_examples = [InputExample(row.Index, row.sentence, label = row.label) for row in val.itertuples()]\n",
    "test_examples = [InputExample(row.Index, row.sentence, label = 'OBJ') for row in test.itertuples()]\n",
    "\n",
    "len(train_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "4c1557f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InputExample(sentence_id='f99b5143-70d2-494a-a2f5-c68f10d09d0a', text_a='The trend is expected to reverse as soon as next month.', text_b=None, label='OBJ')"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_examples[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "0ef60414",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_gpu = torch.cuda.device_count()\n",
    "gradient_accumulation_steps = 1\n",
    "train_batch_size = 32\n",
    "eval_batch_size = 128\n",
    "train_batch_size = train_batch_size // gradient_accumulation_steps\n",
    "output_dir = 'output'\n",
    "bert_model = 'bert-base-chinese'\n",
    "num_train_epochs = 3\n",
    "num_train_optimization_steps = int(\n",
    "            len(train_examples) / train_batch_size / gradient_accumulation_steps) * num_train_epochs\n",
    "cache_dir = \"model\"\n",
    "learning_rate = 5e-5\n",
    "warmup_proportion = 0.1\n",
    "max_seq_length = 128\n",
    "label_list = ['unrelated', 'agreed', 'disagreed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "0e90491d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pytorch_pretrained_bert.tokenization.BertTokenizer at 0x7fde2554b160>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "26e28099",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(BertForSequenceClassification(\n",
       "   (bert): BertModel(\n",
       "     (embeddings): BertEmbeddings(\n",
       "       (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "       (position_embeddings): Embedding(512, 768)\n",
       "       (token_type_embeddings): Embedding(2, 768)\n",
       "       (LayerNorm): BertLayerNorm()\n",
       "       (dropout): Dropout(p=0.1, inplace=False)\n",
       "     )\n",
       "     (encoder): BertEncoder(\n",
       "       (layer): ModuleList(\n",
       "         (0-11): 12 x BertLayer(\n",
       "           (attention): BertAttention(\n",
       "             (self): BertSelfAttention(\n",
       "               (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "             (output): BertSelfOutput(\n",
       "               (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (LayerNorm): BertLayerNorm()\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (intermediate): BertIntermediate(\n",
       "             (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "           )\n",
       "           (output): BertOutput(\n",
       "             (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (LayerNorm): BertLayerNorm()\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (pooler): BertPooler(\n",
       "       (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "       (activation): Tanh()\n",
       "     )\n",
       "   )\n",
       "   (dropout): Dropout(p=0.1, inplace=False)\n",
       "   (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       " ),\n",
       " BertTokenizerFast(name_or_path='bert-base-uncased', vocab_size=30522, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True))"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased',\n",
    "              cache_dir=cache_dir,\n",
    "              num_labels = 3)\n",
    "model.to(device)\n",
    "if n_gpu > 1:\n",
    "    model = torch.nn.DataParallel(model)\n",
    "model, tokenizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "5d80a5ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ahmad/exit/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AdamW\n",
    "param_optimizer = list(model.named_parameters())\n",
    "no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "    ]\n",
    "optimizer = AdamW(optimizer_grouped_parameters,\n",
    "                             lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "28574577",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import PreTrainedTokenizer\n",
    "\n",
    "def convert_examples_to_features(\n",
    "    examples: List[InputExample],\n",
    "    label_list: List[str],\n",
    "    max_length: int,\n",
    "    tokenizer: PreTrainedTokenizer,\n",
    "):\n",
    "    \"\"\"\n",
    "    Loads a data file into a list of ``InputFeatures``\n",
    "\n",
    "    Args:\n",
    "        examples: List of ``InputExamples`` containing the examples.\n",
    "        label_list: List of labels. Can be obtained from the processor using the ``processor.get_labels()`` method.\n",
    "        max_length: Maximum example length.\n",
    "        tokenizer: Instance of a tokenizer that will tokenize the examples.\n",
    "\n",
    "    Returns:\n",
    "        A list of task-specific ``InputFeatures`` which can be fed to the model.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    label_map = {label: i for i, label in enumerate(label_list)}\n",
    "\n",
    "    features = []\n",
    "    for ex_index, example in tqdm.tqdm(enumerate(examples), desc=\"convert examples to features\"):\n",
    "        if ex_index % 10000 == 0:\n",
    "            logger.info(\"Writing example %d\" % (ex_index))\n",
    "\n",
    "        inputs = tokenizer(\n",
    "            example.text_a,\n",
    "            add_special_tokens=True,\n",
    "            max_length=max_length,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_overflowing_tokens=True,\n",
    "        )\n",
    "\n",
    "        label = label_map[example.label] if example.label in label_map else 0\n",
    "\n",
    "        sentenceID = example.sentence_id\n",
    "        features.append(InputFeatures(**inputs, label=label, sentence_id=sentenceID))\n",
    "\n",
    "    for i, example in enumerate(examples[:5]):\n",
    "        logger.info(\"*** Example ***\")\n",
    "        logger.info(f\"guid: {example}\")\n",
    "        logger.info(f\"features: {features[i]}\")\n",
    "\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "a12918dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(frozen=True)\n",
    "class InputFeatures:\n",
    "    \"\"\"\n",
    "    A single set of features of data.\n",
    "    Property names are the same names as the corresponding inputs to a model.\n",
    "\n",
    "    Args:\n",
    "        input_ids: Indices of input sequence tokens in the vocabulary.\n",
    "        attention_mask: Mask to avoid performing attention on padding token indices.\n",
    "            Mask values selected in ``[0, 1]``:\n",
    "            Usually  ``1`` for tokens that are NOT MASKED, ``0`` for MASKED (padded) tokens.\n",
    "        token_type_ids: (Optional) Segment token indices to indicate first and second\n",
    "            portions of the inputs. Only some models use them.\n",
    "        label: (Optional) Label corresponding to the input. Int for classification problems,\n",
    "            float for regression problems.\n",
    "        pairID: (Optional) Unique identifier for the pair of sentences.\n",
    "    \"\"\"\n",
    "\n",
    "    input_ids: List[str]\n",
    "    attention_mask: Optional[List[int]] = None\n",
    "    token_type_ids: Optional[List[int]] = None\n",
    "    overflow_to_sample_mapping: Optional[List[int]] = None  \n",
    "    label: Optional[Union[int, float]] = None\n",
    "    sentence_id: Optional[int] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a3e898",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "convert examples to features: 830it [00:00, 9823.31it/s]\n",
      "Epoch:   0%|                                              | 0/3 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "import logging\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, RandomSampler, DataLoader\n",
    "from tqdm import trange \n",
    "logger = logging.getLogger(__name__)\n",
    "global_step = 0\n",
    "nb_tr_steps = 0\n",
    "tr_loss = 0\n",
    "\n",
    "train_features = convert_examples_to_features(\n",
    "    train_examples, label_list, max_seq_length, tokenizer)\n",
    "logger.info(\"***** Running training *****\")\n",
    "logger.info(\"  Num examples = %d\", len(train_examples))\n",
    "logger.info(\"  Batch size = %d\", train_batch_size)\n",
    "logger.info(\"  Num steps = %d\", num_train_optimization_steps)\n",
    "all_input_ids = torch.tensor([f.input_ids[0] for f in train_features], dtype=torch.long)\n",
    "all_input_mask = torch.tensor([f.attention_mask[0] for f in train_features], dtype=torch.long)\n",
    "all_segment_ids = torch.tensor([f.token_type_ids[0] for f in train_features], dtype=torch.long)\n",
    "# all_label_ids = torch.tensor([hash(f.sentence_id) for f in train_features], dtype=torch.long)\n",
    "train_data = TensorDataset(all_input_ids, all_input_mask, all_segment_ids)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=train_batch_size)\n",
    "\n",
    "model.train()\n",
    "for _ in trange(int(num_train_epochs), desc=\"Epoch\"):\n",
    "    tr_loss = 0\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "    total_step = len(train_data) // train_batch_size\n",
    "    ten_percent_step = total_step // 10\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        input_ids, input_mask, segment_ids = batch\n",
    "        loss = model(input_ids, segment_ids, input_mask)\n",
    "        if n_gpu > 1:\n",
    "            loss = loss.mean() # mean() to average on multi-gpu.\n",
    "        if gradient_accumulation_steps > 1:\n",
    "            loss = loss / gradient_accumulation_steps\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        tr_loss += loss.item()\n",
    "        nb_tr_examples += input_ids.size(0)\n",
    "        nb_tr_steps += 1\n",
    "        if (step + 1) % gradient_accumulation_steps == 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            global_step += 1\n",
    "            \n",
    "        if step % ten_percent_step == 0:\n",
    "            print(\"Fininshed: {:.2f}% ({}/{})\".format(step/total_step*100, step, total_step))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "b2b80952",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'f99b5143-70d2-494a-a2f5-c68f10d09d0a'"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features[1].sentence_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "062b9f05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1501710073152371257\n"
     ]
    }
   ],
   "source": [
    "id_string = \"f99b5143-70d2-494a-a2f5-c68f10d09d0a\"\n",
    "numeric_value = hash(id_string)\n",
    "print(numeric_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7859eac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
